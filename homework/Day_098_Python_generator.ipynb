{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.5"},"colab":{"name":"Day_098_Python_generator.ipynb","provenance":[],"collapsed_sections":["ENw6sIAZ0OrM"]}},"cells":[{"cell_type":"markdown","metadata":{"id":"Rm6zRXMa0OqH","colab_type":"text"},"source":["## Generator 可以使用 next 來進行循環中的一步\n","文字上有點難解釋，直接來看範例就能了解什麼是 Generator!"]},{"cell_type":"markdown","metadata":{"id":"1e-y6RG00OqK","colab_type":"text"},"source":["### 撰寫一個 Generator，一次吐出 list 中的一個值"]},{"cell_type":"code","metadata":{"id":"cF-k0SuG0OqL","colab_type":"code","colab":{}},"source":["def output_from_list_generator(your_list):\n","    for i in your_list:\n","        yield i "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dzwwq8pn0OqO","colab_type":"code","colab":{}},"source":["my_list = [1, 2, 3, 4, 5]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"N0Jmno200OqQ","colab_type":"code","colab":{}},"source":["gen = output_from_list_generator(my_list)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GsX40XiD0OqS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"517e5f4a-be14-4f6b-baa0-1f351ecd19a2","executionInfo":{"status":"ok","timestamp":1576837132903,"user_tz":-480,"elapsed":2562,"user":{"displayName":"董筱君","photoUrl":"","userId":"12311445310352924610"}}},"source":["print(next(gen))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Go5Ufr4f0OqV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"d2265c49-73ed-417a-b799-eef52f038ea3","executionInfo":{"status":"ok","timestamp":1576837132904,"user_tz":-480,"elapsed":2553,"user":{"displayName":"董筱君","photoUrl":"","userId":"12311445310352924610"}}},"source":["print(next(gen))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"woXb8RzI0OqX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"d36a6c3c-5420-4ae9-bad6-2ff9e77a24c0","executionInfo":{"status":"ok","timestamp":1576837132905,"user_tz":-480,"elapsed":2533,"user":{"displayName":"董筱君","photoUrl":"","userId":"12311445310352924610"}}},"source":["print(next(gen))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cXkM3JaZ0OqZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"ece7835a-61b1-4e1c-acac-2d9fae99fc83","executionInfo":{"status":"ok","timestamp":1576837132905,"user_tz":-480,"elapsed":2523,"user":{"displayName":"董筱君","photoUrl":"","userId":"12311445310352924610"}}},"source":["print(next(gen))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zxb4_6cU0Oqb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"616a0deb-0ac4-4903-95ff-4158267843ab","executionInfo":{"status":"ok","timestamp":1576837132906,"user_tz":-480,"elapsed":2514,"user":{"displayName":"董筱君","photoUrl":"","userId":"12311445310352924610"}}},"source":["print(next(gen))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Eq0PvM4x0Oqe","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":166},"outputId":"f126ae7b-1ecb-46e6-97f2-3c5cc8f2e5c7","executionInfo":{"status":"error","timestamp":1576837132918,"user_tz":-480,"elapsed":2513,"user":{"displayName":"董筱君","photoUrl":"","userId":"12311445310352924610"}}},"source":["print(next(gen))"],"execution_count":9,"outputs":[{"output_type":"error","ename":"StopIteration","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-be0d7584d73f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mStopIteration\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"jgvhN0t-0Oqi","colab_type":"text"},"source":["### 從上面的範例程式碼我們可以看到，當使用一次 next，generator 就會跑 for_loop 一次，因此得到 list 中的第一個值，當再使用一次後，for_loop 記得上次的循環，所以吐出第二個值。最後一次，因為 for loop 已經執行結束了，所以再使用 next 就會看到 StopIteration，無法在得到值"]},{"cell_type":"markdown","metadata":{"id":"WPaIMNYs0Oqk","colab_type":"text"},"source":["### 我們可以撰寫一個無限循環的 Generator，只要使用 While True 即可"]},{"cell_type":"code","metadata":{"id":"3_eApj2X0Oql","colab_type":"code","colab":{}},"source":["def inf_loop_generator(your_list):\n","    while True:\n","        for i in your_list:\n","            yield i"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xmtut3BM0Oqp","colab_type":"code","colab":{}},"source":["gen = inf_loop_generator(my_list)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vS1qZloJ0Oqu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"303bd81e-2763-4bec-869d-929d45fe9841","executionInfo":{"status":"ok","timestamp":1576837179744,"user_tz":-480,"elapsed":1271,"user":{"displayName":"董筱君","photoUrl":"","userId":"12311445310352924610"}}},"source":["print(next(gen))"],"execution_count":13,"outputs":[{"output_type":"stream","text":["1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hsOoisVo0Oqy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"aa4c9e02-316d-4eea-88f0-466fc01d0b99","executionInfo":{"status":"ok","timestamp":1576837179745,"user_tz":-480,"elapsed":760,"user":{"displayName":"董筱君","photoUrl":"","userId":"12311445310352924610"}}},"source":["print(next(gen))"],"execution_count":14,"outputs":[{"output_type":"stream","text":["2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PyNsJCtB0Oq3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"9f1f9239-af0f-40c0-f089-b9e6d44203a6","executionInfo":{"status":"ok","timestamp":1576837181848,"user_tz":-480,"elapsed":765,"user":{"displayName":"董筱君","photoUrl":"","userId":"12311445310352924610"}}},"source":["print(next(gen))"],"execution_count":15,"outputs":[{"output_type":"stream","text":["3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"u6qMMynq0Oq7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"f6d8f5fe-26c1-4358-9350-3f25ee5f2ba2","executionInfo":{"status":"ok","timestamp":1576837183246,"user_tz":-480,"elapsed":981,"user":{"displayName":"董筱君","photoUrl":"","userId":"12311445310352924610"}}},"source":["print(next(gen))"],"execution_count":17,"outputs":[{"output_type":"stream","text":["5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6EKjUbyo0OrA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"c8ffa281-0806-46af-d8a1-a259d74edf3a","executionInfo":{"status":"ok","timestamp":1576837184612,"user_tz":-480,"elapsed":662,"user":{"displayName":"董筱君","photoUrl":"","userId":"12311445310352924610"}}},"source":["print(next(gen))"],"execution_count":18,"outputs":[{"output_type":"stream","text":["1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ccg6_Tku0OrE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"418fb967-fd7e-4e69-e83c-3f24a01c20e5","executionInfo":{"status":"ok","timestamp":1576837189185,"user_tz":-480,"elapsed":859,"user":{"displayName":"董筱君","photoUrl":"","userId":"12311445310352924610"}}},"source":["print(next(gen))"],"execution_count":20,"outputs":[{"output_type":"stream","text":["3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9CsnNgWQ0OrJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"f4a0f16f-003d-4076-920d-67e937e1e3d5","executionInfo":{"status":"ok","timestamp":1576837186368,"user_tz":-480,"elapsed":652,"user":{"displayName":"董筱君","photoUrl":"","userId":"12311445310352924610"}}},"source":["print(next(gen))"],"execution_count":19,"outputs":[{"output_type":"stream","text":["2\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ENw6sIAZ0OrM","colab_type":"text"},"source":["### 上面的程式碼因為我們使用了 While True，所以 for loop 不會結束，只要 call next 就一定會跑一次循環，並返回值"]},{"cell_type":"code","metadata":{"id":"U89nObyx0OrN","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QTVay89J0OrR","colab_type":"text"},"source":["## 雖然 Cifar-10 的資料可以全部讀進記憶體，但讓我們試著用 Generator，批次的把 Cifar 10 的資料取出來，一次取 32 張出來！"]},{"cell_type":"code","metadata":{"id":"B5xR0RSj0OrS","colab_type":"code","colab":{}},"source":["def img_combine(img, ncols=8, size=1, path=False):\n","    from math import ceil\n","    import matplotlib.pyplot as plt\n","    import numpy as np\n","    nimg = len(img)\n","    nrows = int(ceil(nimg/ncols))\n","    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, sharex=True, sharey=True, figsize=(ncols*size,nrows*size))\n","    if nrows == 0:\n","        return\n","    elif ncols == 1:\n","        for r, ax in zip(np.arange(nrows), axes):\n","            nth=r\n","            if nth < nimg:\n","                ax.imshow(img[nth], cmap='rainbow', vmin=0, vmax=1)\n","                \n","            ax.set_axis_off()\n","    elif nrows == 1:\n","        for c, ax in zip(np.arange(ncols), axes):\n","            nth=c\n","            if nth < nimg:\n","                ax.imshow(img[nth], cmap='rainbow', vmin=0, vmax=1)\n","            ax.set_axis_off()\n","    else:\n","        for r, row in zip(np.arange(nrows), axes):\n","            for c, ax in zip(np.arange(ncols), row):\n","                nth=r*ncols+c\n","                if nth < nimg:\n","                    ax.imshow(img[nth], cmap='rainbow', vmin=0, vmax=1)\n","                ax.set_axis_off()\n","    plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"b7JwXCEJ0OrV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":81},"outputId":"e4c1e2b7-dc8c-42a2-b540-448d978409ff","executionInfo":{"status":"ok","timestamp":1576837198204,"user_tz":-480,"elapsed":2244,"user":{"displayName":"董筱君","photoUrl":"","userId":"12311445310352924610"}}},"source":["from keras.datasets import cifar10"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"HrqLhVHM0OrY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"0a040fb1-130b-4402-94de-e23daf215f77","executionInfo":{"status":"ok","timestamp":1576837205269,"user_tz":-480,"elapsed":8608,"user":{"displayName":"董筱君","photoUrl":"","userId":"12311445310352924610"}}},"source":["(x_train, x_test), (y_train, y_test) = cifar10.load_data()"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 4s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3WYTO1Qf0Ora","colab_type":"code","colab":{}},"source":["def cifar_generator(image_array, batch_size=32):\n","    while True:\n","        for indexs in range(0, len(image_array), batch_size):\n","            images = x_train[indexs: indexs+batch_size]\n","            labels = x_test[indexs: indexs+batch_size]\n","            yield images, labels"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ruAtnZ340Orb","colab_type":"code","colab":{}},"source":["cifar_gen = cifar_generator(x_train)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UXVLVxAk0Org","colab_type":"code","colab":{}},"source":["images, labels = next(cifar_gen)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zloh19NF0Orj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":166},"outputId":"da68ade1-168f-4e79-d4ae-d75d1c92f418","executionInfo":{"status":"error","timestamp":1576837207512,"user_tz":-480,"elapsed":6012,"user":{"displayName":"董筱君","photoUrl":"","userId":"12311445310352924610"}}},"source":["img_combine(images)"],"execution_count":26,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-a0a46b3a5d1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg_combine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'img_combine' is not defined"]}]},{"cell_type":"code","metadata":{"id":"R74kjQCK0Orn","colab_type":"code","colab":{}},"source":["images, labels = next(cifar_gen)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"v4rJOdeW0Orp","colab_type":"code","colab":{}},"source":["img_combine(images)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XBhkbhsx0Orr","colab_type":"text"},"source":["## 可以看到兩次的圖片並不一樣，這樣就可以開始訓練囉！"]},{"cell_type":"markdown","metadata":{"id":"q5ZW9vQZ0Ors","colab_type":"text"},"source":["## 作業"]},{"cell_type":"markdown","metadata":{"id":"A3xsbUEG0Ort","colab_type":"text"},"source":["請參考昨天的程式碼，將訓練資料讀取方式改寫成 Generator，並將原本的 model.fit 改為 model.fit_generator 來進行訓練。請參考 Keras [官方文件中 fit_generator 的說明](https://keras.io/models/sequential/)"]},{"cell_type":"code","metadata":{"id":"iZxrRAUe0Ort","colab_type":"code","colab":{}},"source":["import keras\n","from keras.datasets import cifar10\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras.optimizers import RMSprop, Adam\n","import os"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cHVjkuCu0Orv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":69},"outputId":"dcd2b216-4cd8-40ca-c563-d6dbb9aeda65","executionInfo":{"status":"ok","timestamp":1576837209262,"user_tz":-480,"elapsed":1736,"user":{"displayName":"董筱君","photoUrl":"","userId":"12311445310352924610"}}},"source":["batch_size = 128 # batch 的大小，如果出現 OOM error，請降低這個值\n","num_classes = 10 # 類別的數量，Cifar 10 共有 10 個類別\n","epochs = 10 # 訓練的 epochs 數量\n","\n","# 讀取資料並檢視\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","\n","# 對 label 進行 one-hot encoding (y_trian 原本是純數字)\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)"],"execution_count":28,"outputs":[{"output_type":"stream","text":["x_train shape: (50000, 32, 32, 3)\n","50000 train samples\n","10000 test samples\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MznVhhtf0Ory","colab_type":"code","colab":{}},"source":["def cifar_generator(image_array, batch_size=32):\n","    while True:\n","        for indexs in range(0, len(image_array), batch_size):\n","            images = x_train[indexs: indexs+batch_size]\n","            labels = y_train[indexs: indexs+batch_size]\n","            yield images, labels"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QRlkXfcw0Or1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"a0607a2f-c148-41ad-b1fe-d8b4defc9223","executionInfo":{"status":"ok","timestamp":1576838653487,"user_tz":-480,"elapsed":1444596,"user":{"displayName":"董筱君","photoUrl":"","userId":"12311445310352924610"}}},"source":["model = Sequential()\n","model.add(Conv2D(32, (3, 3), padding='same',\n","                 input_shape=x_train.shape[1:]))\n","model.add(Activation('relu'))\n","model.add(Conv2D(32, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Conv2D(64, (3, 3), padding='same'))\n","model.add(Activation('relu'))\n","model.add(Conv2D(64, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Flatten())\n","model.add(Dense(512))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(num_classes))\n","model.add(Activation('softmax'))\n","model.summary()\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=RMSprop(),\n","              metrics=['accuracy'])\n","\n","#history = model.fit(x_train, y_train,\n","#                    batch_size=batch_size,\n","#                    epochs=epochs,\n","#                    verbose=1,\n","#                    validation_data=(x_test, y_test))\n","\n","history = model.fit_generator(cifar_generator(x_train),\n","                    steps_per_epoch=len(x_train) // batch_size,\n","                    epochs=20,\n","                    verbose=1,\n","                    validation_data=(x_test, y_test))\n","\n","score = model.evaluate(x_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":30,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n","_________________________________________________________________\n","activation_1 (Activation)    (None, 32, 32, 32)        0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n","_________________________________________________________________\n","activation_2 (Activation)    (None, 30, 30, 32)        0         \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n","_________________________________________________________________\n","activation_3 (Activation)    (None, 15, 15, 64)        0         \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n","_________________________________________________________________\n","activation_4 (Activation)    (None, 13, 13, 64)        0         \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 2304)              0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 512)               1180160   \n","_________________________________________________________________\n","activation_5 (Activation)    (None, 512)               0         \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 10)                5130      \n","_________________________________________________________________\n","activation_6 (Activation)    (None, 10)                0         \n","=================================================================\n","Total params: 1,250,858\n","Trainable params: 1,250,858\n","Non-trainable params: 0\n","_________________________________________________________________\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","Epoch 1/20\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","390/390 [==============================] - 75s 192ms/step - loss: 14.4912 - acc: 0.1006 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 2/20\n","390/390 [==============================] - 71s 181ms/step - loss: 14.4662 - acc: 0.1025 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 3/20\n","390/390 [==============================] - 70s 180ms/step - loss: 14.5295 - acc: 0.0986 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 4/20\n","390/390 [==============================] - 71s 181ms/step - loss: 14.5218 - acc: 0.0990 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 5/20\n","390/390 [==============================] - 71s 182ms/step - loss: 14.5153 - acc: 0.0994 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 6/20\n","390/390 [==============================] - 71s 182ms/step - loss: 14.4650 - acc: 0.1026 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 7/20\n","390/390 [==============================] - 71s 181ms/step - loss: 14.5179 - acc: 0.0993 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 8/20\n","390/390 [==============================] - 71s 181ms/step - loss: 14.5269 - acc: 0.0987 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 9/20\n","390/390 [==============================] - 71s 181ms/step - loss: 14.5102 - acc: 0.0998 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 10/20\n","390/390 [==============================] - 71s 182ms/step - loss: 14.4779 - acc: 0.1018 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 11/20\n","390/390 [==============================] - 72s 184ms/step - loss: 14.5127 - acc: 0.0996 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 12/20\n","390/390 [==============================] - 74s 190ms/step - loss: 14.5347 - acc: 0.0982 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 13/20\n","390/390 [==============================] - 74s 191ms/step - loss: 14.4985 - acc: 0.1005 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 14/20\n","390/390 [==============================] - 74s 190ms/step - loss: 14.4766 - acc: 0.1018 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 15/20\n","390/390 [==============================] - 73s 188ms/step - loss: 14.5192 - acc: 0.0992 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 16/20\n","390/390 [==============================] - 71s 181ms/step - loss: 14.5295 - acc: 0.0986 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 17/20\n","390/390 [==============================] - 71s 182ms/step - loss: 14.4947 - acc: 0.1007 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 18/20\n","390/390 [==============================] - 71s 181ms/step - loss: 14.4792 - acc: 0.1017 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 19/20\n","390/390 [==============================] - 70s 181ms/step - loss: 14.5192 - acc: 0.0992 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 20/20\n","390/390 [==============================] - 70s 180ms/step - loss: 14.5295 - acc: 0.0986 - val_loss: 14.5063 - val_acc: 0.1000\n","Test loss: 14.506285662841798\n","Test accuracy: 0.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lskzx44J0Or5","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"roEqriYD0Or9","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}